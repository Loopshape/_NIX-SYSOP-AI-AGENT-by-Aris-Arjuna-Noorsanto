#!/usr/bin/env bash
# ~/.bin/ai - AI CLI with DB-based module loader
set -euo pipefail
IFS=$'\n\t'

AI_HOME="${HOME}/.local_ai"
DB="$AI_HOME/core.db"
SANDBOX="$AI_HOME/sandbox"
SWAP="$AI_HOME/swap"
mkdir -p "$SANDBOX" "$SWAP" "$AI_HOME/modules"

log() { echo "[$(date '+%H:%M:%S')] $*"; }

# Load environment variables
[ -f "$HOME/.env.local" ] && source "$HOME/.env.local"
log "Environment loaded from ~/.env.local"

# Ensure database exists
if [ ! -f "$DB" ]; then
    log "[!] Core DB missing. Run AI installer first."
    exit 1
fi

# Load modules from DB
declare -A MODULES
while IFS=$'\t' read -r name code; do
    MODULES["$name"]="$code"
done < <(sqlite3 -separator $'\t' "$DB" "SELECT name, code FROM modules;")
log "✅ Loaded ${#MODULES[@]} modules from DB"

# Self-healing: ensure required tools are installed (apt preferred)
required_tools=(python3 git sqlite3 nodejs build-essential wget curl)
for t in "${required_tools[@]}"; do
    if ! command -v "$t" >/dev/null 2>&1; then
        log "[!] Missing $t. Installing via apt..."
        sudo apt update && sudo apt install -y "$t"
    fi
done

# Start Ollama if not running
if ! pgrep -x ollama >/dev/null 2>&1; then
    mkdir -p "$HOME/logs"
    nohup ollama serve > "$HOME/logs/ollama_server.log" 2>&1 &
    log "✅ Started Ollama server"
fi

# Enforce English/German only; auto-translate Chinese
user_input="${1:-}"
if [ -z "$user_input" ]; then
    echo "Usage: ai 'your prompt'"
    exit 0
fi

# Prepare JSON input for Ollama
prompt=$(cat <<EOF
{
  "prompt": "$user_input",
  "language": "en,de",
  "translate_chinese": true
}
EOF
)

# Query Ollama
response=$(echo "$prompt" | python3 -c '
import sys, json, subprocess
try:
    inp = json.load(sys.stdin)
    proc = subprocess.run(
        ["ollama", "run", "2244:latest", "--json", inp["prompt"]],
        capture_output=True, text=True, check=True
    )
    r = json.loads(proc.stdout)
    print(r.get("answer",""))
except Exception as e:
    sys.stderr.write(f"[ERROR] {e}\n")
    sys.exit(1)
')

if [ -z "$response" ]; then
    log "[!] No valid JSON response. Check if Ollama server is running."
    exit 1
fi

# Display the AI output
echo -e "\n[AI OUTPUT]\n$response\n"
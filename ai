#!/usr/bin/env bash
# Bulletproof AI CLI for Termux + Proot
set -euo pipefail
IFS=$'\n\t'

AI_HOME="${HOME}/.local_ai"
SWAP="$AI_HOME/swap"         # unused in Termux
SANDBOX="$AI_HOME/sandbox"
TMPFS_DIR="$AI_HOME/tmpfs"
DB="$AI_HOME/core.db"
MODULES_DIR="$AI_HOME/modules"

mkdir -p "$SANDBOX" "$TMPFS_DIR" "$MODULES_DIR"

log(){ echo "[$(date '+%H:%M:%S')] $*"; }

# ------------------------------
# Environment
# ------------------------------
[ -f "$HOME/.env.local" ] && source "$HOME/.env.local"
export DEBIAN_FRONTEND=noninteractive
export LANG="en_US.UTF-8"

# ------------------------------
# Core dependencies
# ------------------------------
log "Installing core dependencies via apt..."
sudo apt update
sudo apt install -y python3-full git curl wget sqlite3 nodejs build-essential || true

# ------------------------------
# tmpfs sandbox (speed-up)
# ------------------------------
mkdir -p "$TMPFS_DIR"
mount -t tmpfs -o size=256M tmpfs "$TMPFS_DIR" 2>/dev/null || log "⚠ tmpfs skipped (normal on Termux)"

# ------------------------------
# Ollama CLI
# ------------------------------
if ! command -v ollama &>/dev/null; then
    log "Downloading Ollama CLI..."
    curl -fsSL -o /tmp/ollama.tar.gz "https://ollama-releases.s3.amazonaws.com/ollama-cli-latest-linux.tar.gz"
    tar -xzf /tmp/ollama.tar.gz -C /tmp
    chmod +x /tmp/ollama
    sudo mv /tmp/ollama /usr/local/bin/
    log "Ollama installed"
fi

# Start Ollama server if not running
if ! pgrep -x ollama >/dev/null 2>&1; then
    nohup ollama serve > "$HOME/logs/ollama_server.log" 2>&1 &
    log "Ollama server started"
fi

# ------------------------------
# Modules download (safe)
# ------------------------------
MODULES=(
  blockchain
  nostr
  lightning
  termux
  proot
  url-parser
  snippet-assembler
)

for m in "${MODULES[@]}"; do
    URL="https://raw.githubusercontent.com/YourGitHubUser/YourRepo/main/modules/$m.sh"
    OUT="$MODULES_DIR/$m.sh"
    log "Downloading module $m..."
    if curl -fsSL "$URL" -o "$OUT"; then
        chmod +x "$OUT"
    else
        log "⚠ Failed to download module $m (404?)"
        echo "# $m not available" > "$OUT"
    fi
done

# ------------------------------
# SQLite DB setup
# ------------------------------
if [ ! -f "$DB" ]; then
    log "Initializing core database..."
    sqlite3 "$DB" <<'SQL'
CREATE TABLE IF NOT EXISTS mindflow(
    id INTEGER PRIMARY KEY,
    session_id TEXT,
    loop_id INTEGER,
    model_name TEXT,
    output TEXT,
    rank INTEGER,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
);
CREATE TABLE IF NOT EXISTS task_logs(
    id INTEGER PRIMARY KEY,
    tool_used TEXT,
    args TEXT,
    output_summary TEXT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
);
CREATE TABLE IF NOT EXISTS cache(
    prompt_hash TEXT PRIMARY KEY,
    final_answer TEXT
);
SQL
fi

# ------------------------------
# AI query handler
# ------------------------------
query="$*"
if [ -z "$query" ]; then
    log "No query provided. Usage: ai 'your prompt'"
    exit 1
fi

# Force English/German only
log "Querying AI (English/German only)..."
response=$(curl -s -X POST "http://127.0.0.1:11434/ask" \
    -H "Content-Type: application/json" \
    -d "{\"prompt\":\"$query\",\"lang\":\"en,de\"}" || true)

# Validate JSON
if echo "$response" | jq . >/dev/null 2>&1; then
    echo "$response" | jq -r '.answer // empty'
else
    log "⚠ No valid JSON response. Check if Ollama server is running."
    echo "$response"
fi
#!/usr/bin/env bash
# ~/.bin/ai - Bulletproof Local AI CLI
set -euo pipefail
IFS=$'\n\t'

AI_HOME="$HOME/.local_ai"
DB="$AI_HOME/core.db"
SANDBOX="$AI_HOME/sandbox"

log() { echo "[$(date '+%H:%M:%S')] $*"; }

# Load environment variables
[ -f "$HOME/.env.local" ] && set -a && source "$HOME/.env.local" && set +a
log "ðŸ”‘ Environment loaded from ~/.env.local"

# Ensure core directories exist
mkdir -p "$AI_HOME" "$SANDBOX"

# --- Check Python & SQLite ---
if ! command -v python3 >/dev/null; then
    log "[ERROR] python3 not found!"
    exit 1
fi
if ! command -v sqlite3 >/dev/null; then
    log "[ERROR] sqlite3 not found!"
    exit 1
fi

# --- Initialize core DB if missing ---
if [ ! -f "$DB" ]; then
    log "ðŸ“¦ Initializing AI core database..."
    sqlite3 "$DB" "
    CREATE TABLE mindflow(
        id INTEGER PRIMARY KEY,
        session_id TEXT,
        loop_id INTEGER,
        model_name TEXT,
        output TEXT,
        rank INTEGER,
        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
    );
    CREATE TABLE task_logs(
        id INTEGER PRIMARY KEY,
        tool_used TEXT,
        args TEXT,
        output_summary TEXT,
        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
    );
    CREATE TABLE cache(
        prompt_hash TEXT PRIMARY KEY,
        final_answer TEXT
    );"
fi

# --- Check Ollama server ---
OLLAMA_PID=$(pgrep -x ollama || true)
if [ -z "$OLLAMA_PID" ]; then
    log "ðŸš€ Starting Ollama server..."
    nohup ollama serve > "$HOME/logs/ollama_server.log" 2>&1 &
    sleep 3
fi

# --- Command processing ---
if [ $# -lt 1 ]; then
    log "[ERROR] No prompt provided. Usage: ai 'your prompt here'"
    exit 1
fi

PROMPT="$*"
# Only English/German allowed
LANG_CHECK=$(echo "$PROMPT" | grep -P "[\p{Han}\p{Katakana}\p{Hiragana}]")
if [ -n "$LANG_CHECK" ]; then
    log "[INFO] Chinese/Korean/Japanese detected in prompt, translating to English..."
    PROMPT="Translate to English: $PROMPT"
fi

# --- Cache lookup ---
PROMPT_HASH=$(echo -n "$PROMPT" | sha256sum | awk '{print $1}')
CACHED=$(sqlite3 "$DB" "SELECT final_answer FROM cache WHERE prompt_hash='$PROMPT_HASH';")
if [ -n "$CACHED" ]; then
    echo "$CACHED"
    exit 0
fi

# --- Run Ollama ---
RESPONSE=$(ollama run 2244:latest --json "$PROMPT" 2>/dev/null || true)
if [ -z "$RESPONSE" ]; then
    log "[ERROR] No valid JSON response from Ollama. Is the server running?"
    exit 1
fi

# --- Extract answer ---
ANSWER=$(python3 - <<PYTHON
import sys, json
try:
    r=json.loads('''$RESPONSE''')
    print(r.get('answer',''))
except Exception:
    sys.exit(1)
PYTHON
)
if [ -z "$ANSWER" ]; then
    log "[ERROR] Ollama returned empty answer."
    exit 1
fi

# --- Save to cache ---
sqlite3 "$DB" "INSERT OR REPLACE INTO cache(prompt_hash, final_answer) VALUES('$PROMPT_HASH','$ANSWER');"

# --- Output ---
echo "$ANSWER"
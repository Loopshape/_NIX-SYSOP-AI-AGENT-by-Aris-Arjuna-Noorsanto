#!/usr/bin/env bash
# ai.sh - AI Autonomic Synthesis Platform v25 (Dynamic Schema Edition)
# A self-aware agent that dynamically manages its own database schema in real-time.

# --- RUNTIME MODE DETECTION: EMBEDDED NODE.JS WEB SERVER ---
if [[ "${1:-}" == "serve" ]]; then
    exec node --input-type=module - "$0" "$@" <<'NODE_EOF'
import http from 'http';
import { exec } from 'child_process';
const PORT = process.env.AI_PORT || 8080;
const AI_SCRIPT_PATH = process.argv[2];
const HTML_UI = `
<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><title>AI Autonomic Synthesis Platform v25</title>
<style>:root{--bg:#0d1117;--text:#c9d1d9;--accent:#58a6ff;--secondary:#8b949e;--border:#30363d;--input-bg:#161b22;--success:#3fb950;--error:#f85149;}
body{font-family:'SF Mono',Consolas,'Courier New',monospace;background:var(--bg);color:var(--text);margin:0;padding:20px;font-size:14px;line-height:1.6;}
.container{max-width:1000px;margin:auto;}h1{color:var(--accent);text-align:center;border-bottom:1px solid var(--border);padding-bottom:15px;}
.terminal{background:var(--input-bg);border:1px solid var(--border);border-radius:6px;padding:15px;margin-top:20px;height:70vh;overflow-y:scroll;display:flex;flex-direction:column;}
.output{flex-grow:1;white-space:pre-wrap;}.input-line{display:flex;border-top:1px solid var(--border);padding-top:10px;margin-top:10px;}
.prompt{color:var(--accent);font-weight:bold;margin-right:10px;}
input{flex-grow:1;background:transparent;border:none;color:var(--text);font-family:inherit;font-size:inherit;outline:none;}
.log{color:var(--secondary);}.success{color:var(--success);}.error{color:var(--error);}</style></head>
<body><div class="container"><h1>ðŸ¤– AI Autonomic Synthesis Platform v25</h1><div class="terminal"><div id="output" class="output"><div class="log">ðŸš€ AI Agent ready. System initialized.</div></div><div class="input-line"><span class="prompt">ai&gt;</span><input type="text" id="commandInput" placeholder="Enter your high-level goal..." autofocus></div></div></div>
<script>
const output=document.getElementById('output'),input=document.getElementById('commandInput');
function addOutput(text,className='log'){const d=document.createElement('div');d.className=className;d.textContent=text;output.appendChild(d);output.scrollTop=output.scrollHeight;}
async function executeCommand(cmd){addOutput(\`ai> \${cmd}\`,'prompt');input.disabled=true;try{const r=await fetch('/api/command',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({command:cmd})}),d=await r.json();const f=d.output.replace(/\\u001b\\[[0-9;]*m/g,'');addOutput(f,d.success?'success':'error');}catch(e){addOutput(\`[CLIENT ERROR] \${e.message}\`,'error');}finally{input.disabled=false;input.focus();}}
input.addEventListener('keypress',e=>{if(e.key==='Enter'){const c=input.value.trim();if(c){executeCommand(c);input.value='';}}});
</script></body></html>`;

http.createServer((req, res) => {
    res.setHeader('Access-Control-Allow-Origin', '*');
    if (req.method === 'OPTIONS') { res.writeHead(204); res.end(); return; }
    if (req.url === '/' && req.method === 'GET') { res.writeHead(200, { 'Content-Type': 'text/html' }); res.end(HTML_UI); return; }
    if (req.url === '/api/command' && req.method === 'POST') {
        let body = '';
        req.on('data', c => body += c.toString());
        req.on('end', () => {
            try {
                const { command } = JSON.parse(body);
                const sanitizedCmd = command.replace(/(["'$`\\])/g, '\\$1');
                exec(`"${AI_SCRIPT_PATH}" "${sanitizedCmd}"`, { timeout: 600000 }, (err, stdout, stderr) => {
                    res.writeHead(200, { 'Content-Type': 'application/json' });
                    if (err) { res.end(JSON.stringify({ success: false, output: `[SERVER ERROR] ${err.message}\n${stderr}` }));
                    } else { res.end(JSON.stringify({ success: true, output: stdout || 'Command executed without output.' })); }
                });
            } catch (e) { res.writeHead(400, { 'Content-Type': 'application/json' }); res.end(JSON.stringify({ success: false, output: 'Invalid JSON request.' })); }
        });
        return;
    }
    res.writeHead(404, { 'Content-Type': 'application/json' });
    res.end(JSON.stringify({ error: 'Not Found' }));
}).listen(PORT, () => console.log(`ðŸŒ AI Web UI is live at: http://localhost:${PORT}`));
NODE_EOF
fi
# --- END OF NODE.JS SERVER BLOCK ---


# --- BASH AGENT CORE (v25) ---
set -euo pipefail
IFS=$'\n\t'

# ---------------- CONFIG ----------------
AI_HOME="${AI_HOME:-$HOME/.ai_agent}"
PROJECTS_DIR="${PROJECTS_DIR:-$HOME/ai_projects}"
LOG_FILE="$AI_HOME/ai.log"
LOG_LEVEL="${LOG_LEVEL:-INFO}"
CORE_DB="$AI_HOME/agent_core.db" # Unified Database

DEFAULT_ROUTER_MODEL="gemma:2b"
DEFAULT_AGGREGATOR_MODEL="llama3.1:8b"
OLLAMA_BIN="$(command -v ollama || echo 'ollama')"

MAX_AGENT_LOOPS=7
MAX_RAM_BYTES=2097152
SWAP_DIR="$AI_HOME/swap"
HMAC_SECRET_KEY="$AI_HOME/secret.key"

# ---------------- COLORS & ICONS ----------------
RED='\033[0;31m'; GREEN='\033[0;32m'; YELLOW='\033[1;33m'; BLUE='\033[0;34m';
PURPLE='\033[0;35m'; CYAN='\033[0;36m'; ORANGE='\033[0;33m'; NC='\033[0m'
ICON_SUCCESS="âœ…"; ICON_WARN="âš ï¸"; ICON_ERROR="âŒ"; ICON_INFO="â„¹ï¸";
ICON_SECURE="ðŸ”‘"; ICON_DB="ðŸ—ƒï¸"; ICON_PLAN="ðŸ“‹"; ICON_THINK="ðŸ¤”"; ICON_EXEC="âš¡"

# ---------------- LOGGING ----------------
log_to_file(){ echo "[$(date '+%Y-%m-%d %H:%M:%S')] [$1] $2" >> "$LOG_FILE"; }
log_debug(){ [[ "$LOG_LEVEL" == "DEBUG" ]] && printf "${PURPLE}[DEBUG][%s]${NC} %s\n" "$(date '+%T')" "$*" >&2 && log_to_file "DEBUG" "$*"; }
log_info(){ [[ "$LOG_LEVEL" =~ ^(DEBUG|INFO)$ ]] && printf "${BLUE}${ICON_INFO} [%s] %s${NC}\n" "$(date '+%T')" "$*" >&2 && log_to_file "INFO" "$*"; }
log_warn(){ printf "${YELLOW}${ICON_WARN} [%s] %s${NC}\n" "$(date '+%T')" "$*" >&2 && log_to_file "WARN" "$*"; }
log_error(){ printf "${RED}${ICON_ERROR} [%s] ERROR: %s${NC}\n" "$(date '+%T')" "$*" >&2 && log_to_file "ERROR" "$*" && exit 1; }
log_success(){ printf "${GREEN}${ICON_SUCCESS} [%s] %s${NC}\n" "$(date '+%T')" "$*" >&2 && log_to_file "SUCCESS" "$*"; }
log_phase() { echo -e "\n${PURPLE}ðŸš€ %s${NC}" "$*" >&2 && log_to_file "PHASE" "$*"; }
export -f log_to_file log_debug log_info log_warn log_error log_success log_phase

# ---------------- INITIALIZATION & HMAC SETUP ----------------
init_environment() {
    mkdir -p "$AI_HOME" "$PROJECTS_DIR" "$SWAP_DIR"
    if [[ ! -f "$HMAC_SECRET_KEY" ]]; then
        log_warn "No HMAC secret key found. Generating a new one..."
        openssl rand -hex 32 > "$HMAC_SECRET_KEY"; chmod 600 "$HMAC_SECRET_KEY"
        log_success "New HMAC secret key created."
    fi
}
calculate_hmac() {
    local data="$1"; local secret; secret=$(<"$HMAC_SECRET_KEY")
    echo -n "$data" | openssl dgst -sha256 -hmac "$secret" | awk '{print $2}'
}

# ---------------- DYNAMIC DATABASE ENVIRONMENT ----------------
sqlite_escape(){ echo "$1" | sed "s/'/''/g"; }

register_schema() {
    local table_name="$1" description="$2" schema_sql="$3"
    log_info "${ICON_DB} Registering new schema: '$table_name'..."
    sqlite3 "$CORE_DB" "$schema_sql" || { log_error "Failed to execute schema SQL for '$table_name'"; return 1; }
    sqlite3 "$CORE_DB" "INSERT OR REPLACE INTO _master_schema (table_name, description, schema_sql) VALUES ('$(sqlite_escape "$table_name")', '$(sqlite_escape "$description")', '$(sqlite_escape "$schema_sql")');"
    log_success "${ICON_DB} Schema '$table_name' registered successfully."
}

init_db() {
    # Step 1: Create the master schema table itself if it doesn't exist.
    sqlite3 "$CORE_DB" "CREATE TABLE IF NOT EXISTS _master_schema (table_name TEXT PRIMARY KEY, description TEXT, schema_sql TEXT, created_at DATETIME DEFAULT CURRENT_TIMESTAMP);"
    
    # Step 2: Use the registration tool to bootstrap essential tables.
    # This ensures the agent's core tables are self-documented.
    local tables_exist; tables_exist=$(sqlite3 "$CORE_DB" "SELECT COUNT(*) FROM _master_schema WHERE table_name IN ('config', 'memories', 'tool_logs');")
    if [[ "$tables_exist" -ne 3 ]]; then
        log_warn "One or more core schemas missing. Bootstrapping..."
        register_schema "config" \
            "Stores key-value configuration for the agent." \
            "CREATE TABLE IF NOT EXISTS config (key TEXT PRIMARY KEY, value TEXT);"
        
        register_schema "memories" \
            "Stores records of prompts and final AI responses for fuzzy cache and long-term memory." \
            "CREATE TABLE IF NOT EXISTS memories (id INTEGER PRIMARY KEY, prompt_hash TEXT, prompt TEXT, response_ref TEXT, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP); CREATE INDEX IF NOT EXISTS idx_prompt_hash ON memories(prompt_hash);"

        register_schema "tool_logs" \
            "Logs every tool execution for auditing and learning." \
            "CREATE TABLE IF NOT EXISTS tool_logs (id INTEGER PRIMARY KEY, task_id TEXT, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP, tool_name TEXT, args TEXT, result TEXT);"
    else
        log_info "${ICON_DB} Core database schemas are already registered."
    fi
}

get_db_schema_for_prompt() {
    log_info "${ICON_DB} Fetching current database schema for AI context..."
    sqlite3 -header -column "$CORE_DB" "SELECT table_name, description FROM _master_schema;"
}

# ---------------- AI & AGI CORE (with Dynamic DB Tools) ----------------
# HASH, SWAP, CACHE functions remain largely the same, but use CORE_DB
hash_string(){ echo -n "$1" | sha256sum | cut -d' ' -f1; }
semantic_hash_prompt(){ echo "$1" | tr '[:upper:]' '[:lower:]' | tr -cs 'a-z0-9' ' ' | tr -s ' ' | sed 's/ ^*//;s/ *$//' | tr ' ' '_'; }
store_output_fast(){ local content="$1"; local hash=$(hash_string "$content"); if (( ${#content} > MAX_RAM_BYTES )); then local f="$SWAP_DIR/$hash.txt.gz"; echo "$content"|gzip>"$f"; echo "$f"; else echo "$content"; fi; }
retrieve_output_fast(){ local ref="$1"; if [[ -f "$ref" ]]; then [[ "$ref"==*.gz ]]&&gzip -dc "$ref"||cat "$ref"; else echo "$ref"; fi; }
get_cached_response(){ local p_hash=$(semantic_hash_prompt "$1"); sqlite3 "$CORE_DB" "SELECT response_ref FROM memories WHERE prompt_hash = '$(sqlite_escape "$p_hash")' ORDER BY timestamp DESC LIMIT 1;"; }
add_to_memory_fast(){ local p_hash="$1" p="$2" ref="$3"; sqlite3 "$CORE_DB" "INSERT INTO memories (prompt_hash, prompt, response_ref) VALUES ('$(sqlite_escape "$p_hash")','$(sqlite_escape "$p")','$(sqlite_escape "$ref")');"; }
export -f hash_string semantic_hash_prompt store_output_fast retrieve_output_fast get_cached_response add_to_memory_fast sqlite_escape

# AI WORKER functions remain the same
ensure_ollama() { if ! curl -s http://localhost:11434/api/tags >/dev/null; then log_info "Starting Ollama..."; nohup "$OLLAMA_BIN" serve >/dev/null 2>&1 & sleep 3; fi; }
run_worker_fast(){
    local model="$1" sys_prompt="$2" prompt="$3"
    local payload=$(jq -nc --arg m "$model" --arg s "$sys_prompt" --arg p "$prompt" '{model:$m,system:$s,prompt:$p,stream:false}')
    local resp_json=$(curl -s --max-time 300 -X POST http://localhost:11434/api/generate -d "$payload")
    if [[ $(echo "$resp_json" | jq -r '.error // empty') ]]; then echo "API_ERROR: $(echo "$resp_json" | jq -r .error)"; else echo "$resp_json" | jq -r .response; fi
}
export -f run_worker_fast ensure_ollama

# DYNAMIC ROUTER remains the same
get_local_models(){ curl -s http://localhost:11434/api/tags | jq -r '.models[].name'; }
run_dynamic_router(){ local p="$1"; local models=$(get_local_models); local r_p="Select top 3 models from list for request. Respond with comma-separated list only.\nModels:\n$models\nRequest:\n$p"; local s=$(run_worker_fast "$DEFAULT_ROUTER_MODEL" "Task Router" "$r_p" | tr -d '[:space:]'); if [[ -z "$s"||"$s"==API_ERROR* ]]; then echo "$DEFAULT_AGGREGATOR_MODEL"; else echo "$s"; fi; }

# ---------------- NEW DEVOPS TOOLSET (DB-CENTRIC) ----------------
tool_db_query() {
    local project_dir="$1" query="$2"
    log_info "${ICON_DB} Executing read-only query: $query"
    if echo "$query" | grep -qiE '(DROP|DELETE|UPDATE|INSERT|ALTER|CREATE)'; then
        echo "Error: Only SELECT queries are allowed with this tool."
        return 1
    fi
    sqlite3 -header -column "$CORE_DB" "$query"
}
tool_db_insert() {
    local project_dir="$1" table_name="$2" data_pairs="$3"
    log_info "${ICON_DB} Inserting data into table '$table_name'"
    local cols=() vals=()
    IFS=',' read -r -a pairs <<< "$data_pairs"
    for pair in "${pairs[@]}"; do
        cols+=("$(echo "$pair" | cut -d'=' -f1)")
        vals+=("'$(sqlite_escape "$(echo "$pair" | cut -d'=' -f2-)")'")
    done
    local cols_str=$(IFS=,; echo "${cols[*]}")
    local vals_str=$(IFS=,; echo "${vals[*]}")
    local sql="INSERT INTO $table_name ($cols_str) VALUES ($vals_str);"
    sqlite3 "$CORE_DB" "$sql" || { echo "Error: Failed to insert data."; return 1; }
    echo "Successfully inserted 1 row into '$table_name'."
}
tool_db_register_schema() {
    local project_dir="$1" name="$2" desc="$3" sql="$4"
    register_schema "$name" "$desc" "$sql"
    echo "Schema for table '$name' has been successfully registered."
}
# Keep general tools as well
tool_run_command() { local proj_dir="$1" cmd="$2"; (cd "$proj_dir" && eval "$cmd") 2>&1 || echo "Command failed."; }
tool_write_file() { local proj_dir="$1" f_path="$2" content="$3"; mkdir -p "$(dirname "$proj_dir/$f_path")"; echo -e "$content">"$proj_dir/$f_path"; echo "File '$f_path' written."; }
export -f tool_db_query tool_db_insert tool_db_register_schema tool_run_command tool_write_file

# ---------------- AUTONOMOUS WORKFLOW ----------------
run_agi_workflow() {
    local user_prompt="$*"
    local project_dir="$PROJECTS_DIR/task-$(date +%s)"
    mkdir -p "$project_dir"; log_success "Project workspace: $project_dir"

    local cached_ref; cached_ref=$(get_cached_response "$user_prompt")
    if [[ -n "$cached_ref" ]]; then
        log_success "Found high-quality match in fuzzy cache."
        echo -e "\n${CYAN}--- Cached Final Answer ---\n${NC}$(retrieve_output_fast "$cached_ref")"; return
    fi

    # The AI's working context will always start with the DB schema
    local db_schema; db_schema=$(get_db_schema_for_prompt)
    local conversation_history="Current Database Schema:\n$db_schema\n\nInitial User Request: $user_prompt"
    local status="IN_PROGRESS"

    for ((i=1; i<=MAX_AGENT_LOOPS; i++)); do
        log_phase "AGI Loop $i/$MAX_AGENT_LOOPS"
        
        local aggregator_prompt="You are the Aggregator AI. Your goal is to achieve the user's request.
First, review the conversation history and current database schema.
Then, decide on the single best tool to use next to make progress.
Your output MUST be in this exact format:
[REASONING] Your step-by-step thought process for choosing the next action.
[TOOL] tool_name <arguments>

If the request is fully solved, your final output must be just: [FINAL_ANSWER] The final answer or summary.

--- CURRENT CONTEXT ---
$conversation_history"
        
        local aggregated_plan; aggregated_plan=$(run_worker_fast "$DEFAULT_AGGREGATOR_MODEL" "Aggregator & Planner" "$aggregator_prompt")
        
        echo -e "${CYAN}${ICON_PLAN} AGGREGATED PLAN:${NC}\n$aggregated_plan"

        if [[ "$aggregated_plan" == *"[FINAL_ANSWER]"* ]]; then status="SUCCESS"; conversation_history+="\n$aggregated_plan"; break; fi
        
        local tool_line; tool_line=$(echo "$aggregated_plan" | grep '\[TOOL\]' | head -n 1)
        if [[ -z "$tool_line" ]]; then log_warn "AI did not choose a tool. Ending loop."; break; fi

        local clean_tool_cmd; clean_tool_cmd=$(echo "${tool_line#\[TOOL\] }" | sed 's/\r$//')
        local ai_hmac; ai_hmac=$(calculate_hmac "$clean_tool_cmd")
        local verified_hmac; verified_hmac=$(calculate_hmac "$clean_tool_cmd")
        if [[ "$ai_hmac" != "$verified_hmac" ]]; then log_error "HMAC MISMATCH!"; status="HMAC_FAILURE"; break; fi
        log_success "${ICON_SECURE} HMAC signature verified."

        local tool_name; tool_name=$(echo "$clean_tool_cmd" | awk '{print $1}')
        local args; args=$(echo "$clean_tool_cmd" | cut -d' ' -f2-)

        local tool_result="User aborted action."
        if confirm_action "$clean_tool_cmd"; then
            if declare -f "tool_$tool_name" > /dev/null; then
                # Correctly pass arguments as separate strings
                tool_result=$(tool_"$tool_name" "$project_dir" $args) || "Tool failed."
            else
                log_error "AI tried to call an unknown tool: '$tool_name'"
                tool_result="Error: Tool '$tool_name' does not exist."
            fi
        fi
        
        conversation_history+="\n$aggregated_plan\n[TOOL_RESULT]\n$tool_result"
    done

    log_phase "AGI Workflow Complete (Status: $status)"
    local final_answer; final_answer=$(echo "$conversation_history" | grep '\[FINAL_ANSWER\]' | head -n 1 | sed 's/\[FINAL_ANSWER\]//')
    if [[ -z "$final_answer" ]]; then final_answer="Workflow finished. Final context:\n$conversation_history"; fi
    
    local final_ref; final_ref=$(store_output_fast "$final_answer")
    add_to_memory_fast "$(semantic_hash_prompt "$user_prompt")" "$user_prompt" "$final_ref"
    echo -e "\n${GREEN}--- Final Answer ---\n${NC}${final_answer}"
}

run_default_init() { log_phase "No prompt given. Scanning context..."; if [[ -d ".git" ]]; then git status; else tree -L 2 . || ls -la; fi; }

# ---------------- HELP & MAIN DISPATCHER ----------------
show_help() {
    cat << EOF
${GREEN}AI Autonomic Synthesis Platform v25 (Dynamic Schema Edition)${NC}
An agent that dynamically manages its own database schema to solve complex tasks.

${CYAN}USAGE:${NC}
  ai serve                             # Start the interactive web UI
  ai "your high-level goal"            # Run the autonomous AGI workflow
  ai                                   # (No prompt) Scan current directory context
  ai --setup                           # Install/verify dependencies
  ai --help                            # Show this help
EOF
}

main() {
    if [[ "${1:-}" == "serve" ]]; then exit 0; fi
    init_environment; init_db

    if [[ $# -eq 0 ]]; then run_default_init; exit 0; fi
    case "${1:-}" in
        --setup|-s)
            log_info "Installing dependencies (sqlite3, git, curl, nodejs, npm, tree, openssl)..."
            if command -v apt-get &>/dev/null; then sudo apt-get update && sudo apt-get install -y sqlite3 git curl nodejs npm tree openssl
            else log_warn "Could not determine package manager. Please install dependencies manually."; fi
            log_success "System dependencies installed." ;;
        --help|-h) show_help ;;
        *) run_agi_workflow "$@" ;;
    esac
}

# --- SCRIPT ENTRY POINT ---
# FIX: Use parameter expansion to safely check for NODE_ENV
if [[ -z "${NODE_ENV:-}" ]]; then
    main "$@"
fi

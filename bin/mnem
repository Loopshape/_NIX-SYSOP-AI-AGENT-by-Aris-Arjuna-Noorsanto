#!/bin/bash

# Enhanced AI Agent with Memory, Web Research, API, and Task Pooling
# Single-file implementation for bash shell

set -e

# Configuration
CONFIG_DIR="$HOME/.ai_agent"
mkdir -p "$CONFIG_DIR"
MEMORY_DB="$CONFIG_DIR/memory.db"
HASH_INDEX="$CONFIG_DIR/hash_index.json"
POOL_INDEX="$CONFIG_DIR/_pool_index.json"
PROJECTS_DIR="$HOME/ai_projects"
mkdir -p "$PROJECTS_DIR"
API_PORT=8080
API_PID_FILE="$CONFIG_DIR/api.pid"

# Model configuration
DEFAULT_MODEL="llama3.1:8b"
AI_MODEL=${AI_MODEL:-$DEFAULT_MODEL}
AI_TEMPERATURE=${AI_TEMPERATURE:-0.7}
AI_TOP_P=${AI_TOP_P:-0.9}
AI_SEED=${AI_SEED:-}

# Color codes for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Initialize SQLite memory database
init_memory_db() {
    if ! command -v sqlite3 &> /dev/null; then
        echo -e "${RED}Error: sqlite3 is required but not installed.${NC}"
        echo "Install with: sudo apt-get install sqlite3"
        exit 1
    fi
    
    sqlite3 "$MEMORY_DB" "
        CREATE TABLE IF NOT EXISTS memories (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            prompt TEXT NOT NULL,
            response TEXT NOT NULL,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            pool_hash TEXT,
            task_hash TEXT
        );
        CREATE TABLE IF NOT EXISTS config (
            key TEXT PRIMARY KEY,
            value TEXT
        );
        CREATE TABLE IF NOT EXISTS hashes (
            type TEXT,
            target TEXT,
            hash TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        );
        CREATE TABLE IF NOT EXISTS api_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            endpoint TEXT,
            method TEXT,
            payload TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        );
    " 2>/dev/null || true
}

# SQLite escape function
sqlite_escape() {
    echo "$1" | sed "s/'/''/g"
}

# Memory functions
add_to_memory() {
    local prompt="$1"
    local response="$2"
    local pool_hash="$3"
    local task_hash="$4"
    
    sqlite3 "$MEMORY_DB" "
        INSERT INTO memories (prompt, response, pool_hash, task_hash) 
        VALUES ('$(sqlite_escape "$prompt")', '$(sqlite_escape "$response")', '$pool_hash', '$task_hash');
    " 2>/dev/null
}

search_memory() {
    local query="$1"
    local limit="${2:-5}"
    
    sqlite3 "$MEMORY_DB" "
        SELECT prompt, response, timestamp, pool_hash 
        FROM memories 
        WHERE prompt LIKE '%$(sqlite_escape "$query")%' OR response LIKE '%$(sqlite_escape "$query")%'
        ORDER BY timestamp DESC 
        LIMIT $limit;
    " 2>/dev/null
}

clear_memory() {
    local confirm
    echo -e "${YELLOW}‚ö†Ô∏è  This will clear ALL memory data.${NC}"
    read -p "Are you sure you want to clear all memory? (y/N): " confirm
    if [[ $confirm == "y" || $confirm == "Y" ]]; then
        sqlite3 "$MEMORY_DB" "DELETE FROM memories; DELETE FROM hashes;" 2>/dev/null
        echo -e "${GREEN}‚úÖ Memory cleared successfully.${NC}"
    else
        echo -e "${BLUE}‚ÑπÔ∏è  Memory clearance cancelled.${NC}"
    fi
}

# Hash generation functions
generate_semantic_hash() {
    local text="$1"
    echo -n "$text" | sha256sum | cut -d' ' -f1 | cut -c1-16
}

generate_instance_hash() {
    local text="$1"
    echo -n "$text-$(date +%s%N)" | sha256sum | cut -d' ' -f1 | cut -c1-16
}

# JSON handling functions (basic implementation for bash)
json_set() {
    local file="$1"
    local key="$2"
    local value="$3"
    
    if [[ ! -f "$file" ]]; then
        echo "{}" > "$file"
    fi
    
    # Simple JSON manipulation using grep/sed (for basic cases)
    if grep -q "\"$key\"" "$file" 2>/dev/null; then
        sed -i "s/\"$key\": *\"[^\"]*\"/\"$key\": \"$value\"/" "$file"
    else
        sed -i "s/}/, \"$key\": \"$value\" }/" "$file"
    fi
}

json_get() {
    local file="$1"
    local key="$2"
    
    if [[ -f "$file" ]]; then
        grep -o "\"$key\": *\"[^\"]*\"" "$file" | cut -d'"' -f4
    fi
}

# Task pooling system
setup_task_pool() {
    local prompt="$1"
    local semantic_hash=$(generate_semantic_hash "$prompt")
    local instance_hash=$(generate_instance_hash "$prompt")
    local pool_dir="$PROJECTS_DIR/$semantic_hash"
    local task_dir="$pool_dir/$instance_hash"
    
    mkdir -p "$task_dir"
    
    # Update pool index with basic JSON handling
    if [[ ! -f "$POOL_INDEX" ]]; then
        echo "{}" > "$POOL_INDEX"
    fi
    
    local current_count=$(json_get "$POOL_INDEX" "$semantic_hash" || echo "0")
    local rehash_count=$((current_count + 1))
    json_set "$POOL_INDEX" "$semantic_hash" "$rehash_count"
    
    echo "$semantic_hash $instance_hash $rehash_count"
}

# Hash management commands
hash_file() {
    local file_path="$1"
    if [[ ! -f "$file_path" ]]; then
        echo -e "${RED}Error: File not found: $file_path${NC}"
        return 1
    fi
    local hash=$(sha256sum "$file_path" | cut -d' ' -f1)
    json_set "$HASH_INDEX" "file_$file_path" "$hash"
    echo -e "${GREEN}File hash: ${hash}${NC}"
}

hash_prompt() {
    local prompt="$1"
    local hash=$(generate_semantic_hash "$prompt")
    json_set "$HASH_INDEX" "prompt_$hash" "$prompt"
    echo -e "${GREEN}Prompt hash: ${hash}${NC}"
}

hash_repo() {
    local repo_path="${1:-.}"
    if [[ ! -d "$repo_path" ]]; then
        echo -e "${RED}Error: Directory not found: $repo_path${NC}"
        return 1
    fi
    local hash=$(find "$repo_path" -type f \( -name "*.go" -o -name "*.py" -o -name "*.js" -o -name "*.json" -o -name "*.sh" \) -exec cat {} \; 2>/dev/null | sha256sum | cut -d' ' -f1)
    json_set "$HASH_INDEX" "repo_$repo_path" "$hash"
    echo -e "${GREEN}Repository hash: ${hash}${NC}"
}

hash_index() {
    if [[ -f "$HASH_INDEX" ]]; then
        cat "$HASH_INDEX"
    else
        echo "{}"
    fi
}

# Configuration management
config_set() {
    local key="$1"
    local value="$2"
    sqlite3 "$MEMORY_DB" "INSERT OR REPLACE INTO config (key, value) VALUES ('$key', '$value');" 2>/dev/null
    echo -e "${GREEN}‚úÖ Config set: $key = $value${NC}"
}

config_get() {
    local key="$1"
    local value=$(sqlite3 "$MEMORY_DB" "SELECT value FROM config WHERE key = '$key';" 2>/dev/null)
    if [[ -n "$value" ]]; then
        echo -e "${BLUE}$key: $value${NC}"
    else
        echo -e "${YELLOW}Config key not found: $key${NC}"
    fi
}

config_view() {
    echo -e "${CYAN}üìã Current Configuration:${NC}"
    sqlite3 "$MEMORY_DB" "SELECT key, value FROM config;" 2>/dev/null | while IFS='|' read key value; do
        echo -e "${BLUE}  $key: $value${NC}"
    done
}

# Web research tools with user confirmation
tool_web_search() {
    local query="$1"
    echo -e "${CYAN}üîç Web search requested for:${NC} $query"
    read -p "Confirm web search? (y/N): " confirm
    if [[ $confirm != "y" && $confirm != "Y" ]]; then
        echo -e "${YELLOW}‚ùå Web search cancelled by user.${NC}"
        return 1
    fi
    
    echo -e "${GREEN}‚úÖ Performing web search for: $query${NC}"
    # Simulate search results
    echo -e "${BLUE}Search results would include relevant information about: $query${NC}"
    echo "1. Overview of $query"
    echo "2. Key concepts and applications"
    echo "3. Recent developments"
    echo "4. Related resources"
}

tool_read_web_page() {
    local url="$1"
    echo -e "${CYAN}üåê Web page read requested:${NC} $url"
    read -p "Confirm reading web page? (y/N): " confirm
    if [[ $confirm != "y" && $confirm != "Y" ]]; then
        echo -e "${YELLOW}‚ùå Web page reading cancelled by user.${NC}"
        return 1
    fi
    
    echo -e "${GREEN}‚úÖ Reading web page: $url${NC}"
    # Simulate page content extraction
    echo -e "${BLUE}Page content would be extracted and analyzed here...${NC}"
    echo "Title: Example Page about AI"
    echo "Content: This page contains valuable information about artificial intelligence applications..."
    echo "Key points: Machine learning, neural networks, AI ethics"
}

# Supervised file operations
tool_write_file() {
    local file_path="$1"
    local content="$2"
    
    echo -e "${CYAN}üìù Write file requested:${NC} $file_path"
    echo -e "${YELLOW}Content preview (first 10 lines):${NC}"
    echo "---"
    echo "$content" | head -10
    echo "---"
    
    read -p "Confirm file write? (y/N): " confirm
    if [[ $confirm != "y" && $confirm != "Y" ]]; then
        echo -e "${YELLOW}‚ùå File write cancelled by user.${NC}"
        return 1
    fi
    
    mkdir -p "$(dirname "$file_path")"
    echo "$content" > "$file_path"
    echo -e "${GREEN}‚úÖ File written successfully: $file_path${NC}"
}

tool_run_command() {
    local command="$1"
    
    echo -e "${CYAN}‚ö° Command execution requested:${NC} $command"
    read -p "Confirm command execution? (y/N): " confirm
    if [[ $confirm != "y" && $confirm != "Y" ]]; then
        echo -e "${YELLOW}‚ùå Command execution cancelled by user.${NC}"
        return 1
    fi
    
    echo -e "${GREEN}‚úÖ Executing command...${NC}"
    eval "$command"
    local exit_code=$?
    echo -e "${BLUE}Command exited with code: $exit_code${NC}"
    return $exit_code
}

# Enhanced worker prompts
MESSENGER_SYSTEM_PROMPT="You are Messenger, the research specialist. Your role is to gather information through web research and analyze data. When encountering research queries, prioritize using web_search for broad research and read_web_page for specific URLs. Consider recent memories and research findings when planning responses. Always seek user confirmation before external actions. Provide detailed, well-researched information."

COMBINATOR_SYSTEM_PROMPT="You are Combinator, the planning specialist. Your role is to analyze research findings from Messenger and create comprehensive plans. Consider the task pool resonance (rehash_count) when planning - higher counts indicate frequently requested tasks that may need optimized solutions. Create step-by-step plans that Trader can execute."

TRADER_SYSTEM_PROMPT="You are Trader, the execution specialist. Your role is to implement plans created by Combinator. You have access to code execution, file operations, and external tools. Always supervise file operations and network requests with user confirmation. Consider memory context and task resonance in your implementations. Provide clear, executable solutions."

# Enhanced run_worker function with memory injection and streaming output
run_worker() {
    local role="$1"
    local prompt="$2"
    local memories="$3"
    local rehash_count="${4:-0}"
    
    local system_prompt=""
    case $role in
        "messenger") system_prompt="$MESSENGER_SYSTEM_PROMPT" ;;
        "combinator") system_prompt="$COMBINATOR_SYSTEM_PROMPT" ;;
        "trader") system_prompt="$TRADER_SYSTEM_PROMPT" ;;
    esac
    
    # Inject memories and resonance into prompt
    local enhanced_prompt="## CONTEXT AND MEMORIES ##
Previous relevant memories:
$memories

## TASK RESONANCE ##
This type of task has been requested $rehash_count times before.

## CURRENT TASK ##
$prompt

## INSTRUCTIONS ##
Think step by step and provide a comprehensive response."

    echo -e "${PURPLE}ü§ñ $role is thinking...${NC}"
    echo -e "${CYAN}=======================${NC}"
    
    # Create temporary file for the prompt
    local temp_prompt=$(mktemp)
    echo "$system_prompt" > "$temp_prompt"
    echo -e "\n$enhanced_prompt" >> "$temp_prompt"
    
    # Stream output while capturing for memory
    local response=""
    local line
    {
        while IFS= read -r line; do
            echo -e "${BLUE}$line${NC}"
            response+="$line"$'\n'
        done
    } < <(ollama run --model "$AI_MODEL" --temperature "$AI_TEMPERATURE" --top-p "$AI_TOP_P" ${AI_SEED:+--seed $AI_SEED} < "$temp_prompt" 2>/dev/null || echo "Error: Failed to get AI response. Check if Ollama is running and model is available.")
    
    rm -f "$temp_prompt"
    
    echo -e "${CYAN}=======================${NC}"
    echo "$response"
}

# Main agent function
run_triumvirate_agent() {
    local user_prompt="$*"
    
    if [[ -z "$user_prompt" ]]; then
        echo -e "${RED}Error: No prompt provided.${NC}"
        return 1
    fi
    
    echo -e "${GREEN}üß† AI Agent Processing:${NC} $user_prompt"
    
    # Initialize memory system
    init_memory_db
    
    # Set up task pooling
    local pool_info=$(setup_task_pool "$user_prompt")
    local semantic_hash=$(echo "$pool_info" | cut -d' ' -f1)
    local instance_hash=$(echo "$pool_info" | cut -d' ' -f2)
    local rehash_count=$(echo "$pool_info" | cut -d' ' -f3)
    
    echo -e "${BLUE}üìä Task pool: $semantic_hash (resonance: $rehash_count)${NC}"
    
    # Search for relevant memories
    local relevant_memories=$(search_memory "$user_prompt")
    local memory_count=$(echo "$relevant_memories" | grep -c "|" || true)
    echo -e "${BLUE}üíæ Retrieved memories: $memory_count relevant entries${NC}"
    
    # Messenger phase - research and information gathering
    echo -e "${YELLOW}üöÄ Starting Messenger phase...${NC}"
    local messenger_response=$(run_worker "messenger" "Research and gather information for: $user_prompt" "$relevant_memories" "$rehash_count")
    
    # Combinator phase - planning with research findings
    echo -e "${YELLOW}üöÄ Starting Combinator phase...${NC}"
    local combinator_response=$(run_worker "combinator" "Create a detailed execution plan using this research: $messenger_response" "$relevant_memories" "$rehash_count")
    
    # Trader phase - execution with supervision
    echo -e "${YELLOW}üöÄ Starting Trader phase...${NC}"
    local trader_response=$(run_worker "trader" "Execute this plan with proper supervision: $combinator_response" "$relevant_memories" "$rehash_count")
    
    # Store in memory
    add_to_memory "$user_prompt" "$trader_response" "$semantic_hash" "$instance_hash"
    
    echo -e "${GREEN}‚úÖ Task completed and stored in memory.${NC}"
    echo -e "${BLUE}üìÅ Task location: $PROJECTS_DIR/$semantic_hash/$instance_hash${NC}"
    
    # Save full response to task directory
    local task_dir="$PROJECTS_DIR/$semantic_hash/$instance_hash"
    echo "User Prompt: $user_prompt" > "$task_dir/full_response.txt"
    echo "Messenger: $messenger_response" >> "$task_dir/full_response.txt"
    echo "Combinator: $combinator_response" >> "$task_dir/full_response.txt"
    echo "Trader: $trader_response" >> "$task_dir/full_response.txt"
}

# API Server implementation
start_api_server() {
    if [[ -f "$API_PID_FILE" ]]; then
        local existing_pid=$(cat "$API_PID_FILE")
        if kill -0 "$existing_pid" 2>/dev/null; then
            echo -e "${YELLOW}‚ö†Ô∏è  API server already running with PID $existing_pid${NC}"
            return
        fi
    fi
    
    echo -e "${GREEN}üöÄ Starting AI Agent API server on port $API_PORT${NC}"
    
    # Simple HTTP server using netcat in background
    {
        while true; do
            {
                read -r line
                # Simple HTTP request parsing
                if [[ "$line" == GET* ]]; then
                    path=$(echo "$line" | cut -d' ' -f2)
                    case "$path" in
                        "/status")
                            echo -e "HTTP/1.1 200 OK\r"
                            echo -e "Content-Type: application/json\r"
                            echo -e "\r"
                            echo -e "{\"status\": \"running\", \"service\": \"ai_agent\", \"timestamp\": \"$(date -Iseconds)\"}"
                            ;;
                        "/health")
                            echo -e "HTTP/1.1 200 OK\r"
                            echo -e "Content-Type: application/json\r"
                            echo -e "\r"
                            echo -e "{\"healthy\": true}"
                            ;;
                        *)
                            echo -e "HTTP/1.1 404 Not Found\r"
                            echo -e "Content-Type: application/json\r"
                            echo -e "\r"
                            echo -e "{\"error\": \"Endpoint not found\"}"
                            ;;
                    esac
                fi
            } | nc -l -p $API_PORT -q 1
        done
    } &
    
    local api_pid=$!
    echo $api_pid > "$API_PID_FILE"
    echo -e "${GREEN}‚úÖ API server started with PID: $api_pid${NC}"
    echo -e "${BLUE}üì° API endpoints:${NC}"
    echo -e "  GET http://localhost:$API_PORT/status"
    echo -e "  GET http://localhost:$API_PORT/health"
}

stop_api_server() {
    if [[ -f "$API_PID_FILE" ]]; then
        local api_pid=$(cat "$API_PID_FILE")
        if kill -0 "$api_pid" 2>/dev/null; then
            kill "$api_pid"
            rm -f "$API_PID_FILE"
            echo -e "${GREEN}‚úÖ API server stopped.${NC}"
        else
            echo -e "${YELLOW}‚ö†Ô∏è  No running API server found.${NC}"
            rm -f "$API_PID_FILE"
        fi
    else
        echo -e "${YELLOW}‚ö†Ô∏è  No API server PID file found.${NC}"
    fi
}

api_status() {
    if [[ -f "$API_PID_FILE" ]]; then
        local api_pid=$(cat "$API_PID_FILE")
        if kill -0 "$api_pid" 2>/dev/null; then
            echo -e "${GREEN}‚úÖ API server is running (PID: $api_pid)${NC}"
            
            # Test the status endpoint
            if command -v curl &> /dev/null; then
                echo -e "${BLUE}Testing API endpoint...${NC}"
                curl -s "http://localhost:$API_PORT/status" | head -c 100
                echo
            fi
        else
            echo -e "${RED}‚ùå API server PID file exists but process is not running.${NC}"
            rm -f "$API_PID_FILE"
        fi
    else
        echo -e "${YELLOW}‚ö†Ô∏è  API server is not running.${NC}"
    fi
}

# Main CLI argument parsing
main() {
    case "${1:-}" in
        "--config")
            case "${2:-}" in
                "view") config_view ;;
                "get") config_get "${3:-}" ;;
                "set") config_set "${3:-}" "${4:-}" ;;
                *) echo -e "${RED}Usage: ai --config [view|get|set]${NC}" ;;
            esac
            ;;
        "--hash")
            case "${2:-}" in
                "file") hash_file "${3:-}" ;;
                "prompt") hash_prompt "${3:-}" ;;
                "repo") hash_repo "${3:-}" ;;
                "index") hash_index ;;
                *) echo -e "${RED}Usage: ai --hash [file|prompt|repo|index]${NC}" ;;
            esac
            ;;
        "--memory")
            case "${2:-}" in
                "search") search_memory "${3:-}" ;;
                "clear") clear_memory ;;
                *) echo -e "${RED}Usage: ai --memory [search|clear]${NC}" ;;
            esac
            ;;
        "--api")
            case "${2:-}" in
                "start") start_api_server ;;
                "stop") stop_api_server ;;
                "status") api_status ;;
                *) echo -e "${RED}Usage: ai --api [start|stop|status]${NC}" ;;
            esac
            ;;
        "--tools")
            echo -e "${CYAN}Available tools:${NC}"
            echo -e "  tool_web_search <query>"
            echo -e "  tool_read_web_page <url>"
            echo -e "  tool_write_file <path> <content>"
            echo -e "  tool_run_command <command>"
            ;;
        "--help"|"-h"|"")
            cat << EOF
${GREEN}Enhanced AI Agent - Single File Implementation${NC}

${CYAN}Basic Usage:${NC}
  ai "your prompt here"          - Run AI agent with prompt
  ai --help                      - Show this help

${CYAN}Configuration:${NC}
  ai --config view               - View all configuration
  ai --config get <key>          - Get configuration value
  ai --config set <key> <value>  - Set configuration

${CYAN}Hashing:${NC}
  ai --hash file <path>          - Hash a file
  ai --hash prompt "text"        - Hash a prompt
  ai --hash repo [path]          - Hash a repository
  ai --hash index                - Show hash index

${CYAN}Memory:${NC}
  ai --memory search "query"     - Search memory
  ai --memory clear              - Clear memory (with confirmation)

${CYAN}API:${NC}
  ai --api start                 - Start REST API server
  ai --api stop                  - Stop API server
  ai --api status                - Check API status

${CYAN}Tools:${NC}
  ai --tools                     - List available tools

${CYAN}Environment Variables:${NC}
  AI_MODEL="llama3.1:8b"         - Set AI model
  AI_TEMPERATURE=0.7             - Set temperature (0-1)
  AI_TOP_P=0.9                   - Set top_p (0-1)
  AI_SEED=                       - Set random seed

${YELLOW}Examples:${NC}
  ai "Explain quantum computing"
  ai --config set temperature 0.5
  ai --hash file ./script.sh
  ai --memory search "python"
  ai --api start

EOF
            ;;
        *)
            # If no recognized flag, treat as prompt
            run_triumvirate_agent "$@"
            ;;
    esac
}

# Check if Ollama is available
check_ollama() {
    if ! command -v ollama &> /dev/null; then
        echo -e "${RED}Error: Ollama is not installed or not in PATH.${NC}"
        echo "Install from: https://ollama.ai"
        exit 1
    fi
}

# Initialize on first run
first_time_setup() {
    if [[ ! -f "$CONFIG_DIR/setup_complete" ]]; then
        echo -e "${GREEN}üéâ First-time setup initializing...${NC}"
        init_memory_db
        config_set "default_model" "$DEFAULT_MODEL"
        config_set "temperature" "$AI_TEMPERATURE"
        config_set "top_p" "$AI_TOP_P"
        touch "$CONFIG_DIR/setup_complete"
        echo -e "${GREEN}‚úÖ Setup completed!${NC}"
    fi
}

# Main execution flow
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    first_time_setup
    check_ollama
    main "$@"
fi

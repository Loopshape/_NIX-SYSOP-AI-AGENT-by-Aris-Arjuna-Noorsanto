#!/usr/bin/env bash
# ai.sh - Custom Models Edition (2244-1, core, loop)
# Optimized for your specific Ollama models

set -euo pipefail
IFS=$'\n\t'

# --- CUSTOM MODEL CONFIGURATION ---
AI_HOME="${AI_HOME:-$HOME/.ai_agent}"
PROJECTS_DIR="${PROJECTS_DIR:-$HOME/ai_projects}"

# Your mandatory models
AGENT_MODEL="2244-1"
REVIEWER_MODEL="core" 
TESTER_MODEL="loop"
FALLBACK_MODEL="2244-1"  # Primary fallback

OLLAMA_BIN="$(command -v ollama || echo 'ollama')"
MEMORY_DB="$AI_HOME/memory.db"

# --- COLORS ---
RED='\033[0;31m'; GREEN='\033[0;32m'; YELLOW='\033[1;33m'
BLUE='\033[0;34m'; PURPLE='\033[0;35m'; CYAN='\033[0;36m'; NC='\033[0m'

log() { echo -e "${BLUE}[$(date '+%T')]${NC} $*"; }
log_success() { echo -e "${GREEN}[$(date '+%T')]${NC} $*"; }
log_warn() { echo -e "${YELLOW}[$(date '+%T')]${NC} $*"; }
log_error() { echo -e "${RED}[$(date '+%T')]${NC} $*"; }
log_ai() { echo -e "${PURPLE}[$(date '+%T')]ðŸ¤–${NC} $*"; }

log_phase() {
    echo -e "\n${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${CYAN} $* ${NC}"
    echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
}

# --- INITIALIZATION ---
mkdir -p "$AI_HOME" "$PROJECTS_DIR"

# --- OLLAMA MANAGEMENT ---
ensure_ollama() {
    if ! command -v ollama >/dev/null 2>&1; then
        log_error "Ollama not found. Install from https://ollama.ai"
        return 1
    fi
    
    # Start Ollama server if not running
    if ! curl -s http://localhost:11434/api/tags >/dev/null 2>&1; then
        log "Starting Ollama server..."
        nohup ollama serve >/dev/null 2>&1 &
        local wait_time=0
        while [ $wait_time -lt 30 ]; do
            if curl -s http://localhost:11434/api/tags >/dev/null 2>&1; then
                log_success "Ollama server started"
                return 0
            fi
            sleep 1
            ((wait_time++))
        done
        log_error "Ollama server failed to start within 30 seconds"
        return 1
    fi
    return 0
}

check_model() {
    local model="$1"
    if ensure_ollama && ollama list | grep -q "$model"; then
        log "Model available: $model"
        return 0
    else
        log_warn "Model not available: $model"
        return 1
    fi
}

get_available_model() {
    # Try specified models in order of preference
    for model in "$AGENT_MODEL" "$REVIEWER_MODEL" "$TESTER_MODEL" "$FALLBACK_MODEL"; do
        if check_model "$model"; then
            echo "$model"
            return 0
        fi
    done
    log_error "No models available. Please ensure at least one model is installed."
    return 1
}

run_model_safe() {
    local preferred_model="$1"
    local prompt="$2"
    local system_prompt="${3:-}"
    
    local model
    if ! model=$(get_available_model); then
        return 1
    fi
    
    # Use preferred model if available, otherwise fallback
    if check_model "$preferred_model"; then
        model="$preferred_model"
    fi
    
    log_ai "Using model: $model"
    
    local full_prompt="$prompt"
    if [[ -n "$system_prompt" ]]; then
        full_prompt="System: $system_prompt\n\nUser: $prompt"
    fi
    
    if output=$(ollama run "$model" "$full_prompt" --temperature 0.3 --top-p 0.9 2>&1); then
        echo "$output"
        return 0
    else
        log_warn "Model $model failed, trying fallback..."
        # Try any available model as fallback
        for fallback in "$AGENT_MODEL" "$REVIEWER_MODEL" "$TESTER_MODEL"; do
            if [[ "$fallback" != "$model" ]] && check_model "$fallback"; then
                if output=$(ollama run "$fallback" "$full_prompt" --temperature 0.3 --top-p 0.9 2>&1); then
                    echo "$output"
                    return 0
                fi
            fi
        done
        log_error "All model attempts failed"
        return 1
    fi
}

# --- MEMORY SYSTEM ---
init_memory() {
    sqlite3 "$MEMORY_DB" "CREATE TABLE IF NOT EXISTS memories (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
        prompt TEXT,
        response TEXT,
        model_used TEXT,
        status TEXT
    );" 2>/dev/null || true
}

save_memory() {
    local prompt="$1" response="$2" model="$3" status="${4:-success}"
    sqlite3 "$MEMORY_DB" "INSERT INTO memories (prompt, response, model_used, status) 
    VALUES ('${prompt//\'/''}', '${response//\'/''}', '$model', '$status');" 2>/dev/null
}

search_memory() {
    local query="$1"
    sqlite3 -header -column "$MEMORY_DB" \
        "SELECT timestamp, prompt, model_used, status FROM memories 
         WHERE prompt LIKE '%$query%' OR response LIKE '%$query%'
         ORDER BY timestamp DESC LIMIT 5;" 2>/dev/null || echo "No memories found"
}

# --- CORE AI WORKFLOWS ---
simple_chat() {
    local prompt="$*"
    log_phase "CHAT MODE"
    
    local response
    if response=$(run_model_safe "$AGENT_MODEL" "$prompt"); then
        echo -e "\n${GREEN}Response:${NC}"
        echo "$response"
        save_memory "$prompt" "$response" "$AGENT_MODEL"
    else
        log_error "Chat failed"
    fi
}

coder_workflow() {
    local prompt="$*"
    log_phase "CODER WORKFLOW"
    
    local project_name=$(echo "$prompt" | tr ' ' '-' | tr -cd 'a-zA-Z0-9-' | cut -c1-20)
    local project_dir="$PROJECTS_DIR/$project_name"
    
    mkdir -p "$project_dir"
    cd "$project_dir"
    log_success "Project: $project_dir"
    
    # Phase 1: Agent generates code
    log_phase "AGENT (2244-1) - Code Generation"
    local code_prompt="Write complete, functional code for: $prompt. Output ONLY the code with comments."
    local code
    if code=$(run_model_safe "$AGENT_MODEL" "$code_prompt" "You are an expert programmer. Write clean, working code."); then
        echo "$code" > "main.py"
        log_success "Code generated: main.py"
    else
        log_error "Code generation failed"
        return 1
    fi
    
    # Phase 2: Core model reviews
    log_phase "REVIEWER (core) - Code Review"
    local review_prompt="Review this code for errors and improvements:\n$code"
    local review
    if review=$(run_model_safe "$REVIEWER_MODEL" "$review_prompt" "You are a code reviewer. Provide constructive feedback."); then
        echo "# Review: $review" >> "review.txt"
        log_success "Review completed"
    else
        log_warn "Review skipped - model unavailable"
    fi
    
    # Phase 3: Loop model tests
    log_phase "TESTER (loop) - Test Generation"
    local test_prompt="Write tests for this code:\n$code"
    local tests
    if tests=$(run_model_safe "$TESTER_MODEL" "$test_prompt" "You are a testing expert. Write comprehensive tests."); then
        echo "$tests" > "test_main.py"
        log_success "Tests generated: test_main.py"
    else
        log_warn "Test generation skipped - model unavailable"
    fi
    
    # Save to memory
    save_memory "$prompt" "Project created: $project_dir" "multi-model" "success"
    
    log_phase "WORKFLOW COMPLETE"
    echo "Project location: $project_dir"
    echo "Files created: main.py, test_main.py, review.txt"
    ls -la "$project_dir"
}

analyze_code() {
    local path="${1:-.}"
    log_phase "CODE ANALYSIS"
    
    if [[ ! -d "$path" && ! -f "$path" ]]; then
        log_error "Path not found: $path"
        return 1
    fi
    
    local analysis_prompt="Analyze the code structure and provide insights for: $path"
    
    if [[ -d "$path" ]]; then
        analysis_prompt="Analyze this directory structure and code quality: $path"
        ls -la "$path" | head -10
    elif [[ -f "$path" ]]; then
        analysis_prompt="Analyze this file and provide code review: $path"
        head -20 "$path"
    fi
    
    local analysis
    if analysis=$(run_model_safe "$REVIEWER_MODEL" "$analysis_prompt" "You are a code analyst. Provide detailed analysis."); then
        echo -e "\n${GREEN}Analysis:${NC}"
        echo "$analysis"
    else
        log_error "Analysis failed"
    fi
}

# --- GIT INTEGRATION ---
git_operations() {
    local operation="$1"
    local path="${2:-.}"
    
    if [[ ! -d "$path/.git" ]]; then
        log_error "Not a git repository: $path"
        return 1
    fi
    
    cd "$path"
    log_phase "GIT $operation: $(basename "$PWD")"
    
    case "$operation" in
        status)
            git status
            echo ""
            git log --oneline -5
            ;;
        pull)
            git pull
            ;;
        log)
            git log --oneline -10 --graph --decorate
            ;;
        branches)
            git branch -a
            ;;
        *)
            log_error "Unknown git operation: $operation"
            echo "Available: status, pull, log, branches"
            ;;
    esac
}

# --- MODEL MANAGEMENT ---
list_models() {
    log_phase "AVAILABLE MODELS"
    if ensure_ollama; then
        ollama list
    else
        log_error "Cannot connect to Ollama"
    fi
}

check_models() {
    log_phase "MODEL STATUS"
    local models=("$AGENT_MODEL" "$REVIEWER_MODEL" "$TESTER_MODEL")
    
    for model in "${models[@]}"; do
        if check_model "$model"; then
            log_success "âœ“ $model"
        else
            log_warn "âœ— $model (not available)"
        fi
    done
}

# --- HELP SYSTEM ---
show_help() {
    cat << EOF
${GREEN}AI DevOps Platform - Custom Models Edition${NC}

${CYAN}MODELS:${NC} 2244-1 (Agent) | core (Reviewer) | loop (Tester)

${CYAN}USAGE:${NC}
  ai chat "your message"        - Simple chat with AI
  ai code "project description" - Full coding workflow
  ai analyze [path]             - Analyze code/directory
  ai git <operation> [path]     - Git operations
  ai models                     - Check model status
  ai memory [search]            - Search memory

${CYAN}GIT OPERATIONS:${NC}
  status    - Repository status
  pull      - Pull latest changes
  log       - Commit history
  branches  - List branches

${CYAN}EXAMPLES:${NC}
  ai chat "Explain quantum computing"
  ai code "Python script for web scraping"
  ai analyze ~/projects/myapp
  ai git status ~/repository
  ai models

${CYAN}MODEL PRIORITY:${NC}
  1. 2244-1 (Primary agent)
  2. core (Reviewer/analyst) 
  3. loop (Tester)
  4. Fallback to any available model
EOF
}

# --- MAIN DISPATCHER ---
main() {
    init_memory
    
    if [[ $# -eq 0 ]]; then
        show_help
        return 0
    fi
    
    case "$1" in
        chat|ask|talk)
            shift
            simple_chat "$@"
            ;;
        code|create|build)
            shift
            coder_workflow "$@"
            ;;
        analyze|review|inspect)
            shift
            analyze_code "${1:-.}"
            ;;
        git)
            shift
            git_operations "${1:-status}" "${2:-.}"
            ;;
        models|status)
            check_models
            list_models
            ;;
        memory|search)
            shift
            search_memory "${1:-}"
            ;;
        help|--help|-h)
            show_help
            ;;
        *)
            # Default to chat
            simple_chat "$@"
            ;;
    esac
}

# --- ENTRY POINT ---
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
